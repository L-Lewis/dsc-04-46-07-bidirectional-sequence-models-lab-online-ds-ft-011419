{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional Sequence Models - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn to make use of **_Bidirectional Models_** to better classify sequences of text!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Understand and explain the basic architecture of a Bidirectional RNN. \n",
    "* Identify the types of problems Bidirectional approaches are best suited for. \n",
    "* Build and train Bidirectional RNN Models. \n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we're going to use a **_Bidrectional LSTM Model_** to build a model that can identify toxic comments on social media. This dataset comes from the [Toxic Comment Classification Challenge on Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) in partnership with Google and Jigsaw.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "From the \"Data\" section of the Kaggle competition linked above:\n",
    "\n",
    "\"You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "\n",
    "* toxic\n",
    "* severe_toxic\n",
    "* obscene\n",
    "* threat\n",
    "* insult\n",
    "* identity_hate\n",
    "\n",
    "You must create a model which predicts a probability of each type of toxicity for each comment.\"\n",
    "\n",
    "This tells us a couple things about the problem, which will affect the overall architecture of our model. Although this may technically be a multiclass classification problem, in practice, our model will treat each comment as 6 concurrent instances of binary classification. This is because a toxic comment can fall into one or more of the categories listed above--for example, a  comment may be toxic, obscene, threatening, and insulting, all at the same time. \n",
    "\n",
    "Run the cell below to import everything we'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We'll start by loading in our training and testing data. You'll find the data stored inside of the file `data.zip` included in this repo. \n",
    "\n",
    "**_NOTE:_**  Before we can begin loading in the data using pandas, you'll first need to unzip the file. Go into the repo you've cloned and unzip the `data` folder into the same directory as this jupyter notebook now.\n",
    "\n",
    "Next, we'll use pandas to load in our training and testing data, and then downsample to only 20% of the training data, in the interest of training time. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Use pandas to read the training data from `data/train.csv`. Store this data in `train`.\n",
    "* Set `train` equal to `train.sample(frac=0.2)`, so that we'll only use 20% of the data to train our model. Otherwise, training this model could take several hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>c6a29bad26183dcf</td>\n",
       "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>befd36e7acca9e56</td>\n",
       "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120969</th>\n",
       "      <td>8734c26db56d1763</td>\n",
       "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121827</th>\n",
       "      <td>8bcf03120412d869</td>\n",
       "      <td>I don't know if this is exactly like the Press...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0ca7b705720d6956</td>\n",
       "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "74251   c6a29bad26183dcf  \"\\nI haven't paraphrased you at all, Gary.  Yo...   \n",
       "131406  befd36e7acca9e56  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...   \n",
       "120969  8734c26db56d1763  I'm sorry. I'd like to unreservedly retract my...   \n",
       "121827  8bcf03120412d869  I don't know if this is exactly like the Press...   \n",
       "4771    0ca7b705720d6956  Thank you all, we'll all improve the Wikipedia...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "74251       0             0        0       0       0              0  \n",
       "131406      1             0        0       0       0              0  \n",
       "120969      0             0        0       0       1              0  \n",
       "121827      0             0        0       0       0              0  \n",
       "4771        0             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74251                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"\\nI haven't paraphrased you at all, Gary.  You complained that preferring recent sources to those \"\"well over 3 years old\"\" is \"\"recentism\"\".  I pointed out that it is strongly encouraged by MEDRS, and for good reason. Again, if you take issue with that, then you need to raise it at the appropriate talk page.   \"\n",
       "131406                                                                                                                                                                                                                                                                                                                                                                                      I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED REVERS!\n",
       "120969                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I'm sorry. I'd like to unreservedly retract my previous statement. You are not in any conceivable way a sad, pathetic loser with nothing better to do with your life than going around trying to censor other people's points of view. I am truly sorry if I in any way suggested or implied that this was the case.\n",
       "121827                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I don't know if this is exactly like the Press Release but you can use this as a source:\\n\\nhttp://tvguide.sympatico.msn.ca/RealityTV/Articles/090624_hells_kitchen_6_contestants_AD\n",
       "4771                                                                                                                                                                                                                                                                                          Thank you all, we'll all improve the Wikipedia in 2007\\nDear all! Thanks for the warm wishes and all the emails that came in while I was at the New Year's vacation.\\n\\nNow that I checked back for what has been going on in the last ten days while I was away the situation seems hopeful indeed. The bunch of scandalous action inspired by the secretive plottings are still being discusses and widely condemned and I see I see a strong momentum of the community of the Wikipedia editors to finally put a decisive end to the secretive activity at the closed channels followed by the drastically insulting onwiki actions. I am also hopeful that the new arbcom will act on the recent developments.  \\n\\nHappy New 2007 to all!\\n ]]\n",
       "79050                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I removed\\nIf V is separable, it follows that any vector in V can be written as a (possibly infinite) linear combination of vectors from S.\\nLinear combinations are by definition finite, so we would have to say a bit more to make this statement precise. Even then, I'm not sure that it is true in general (it surely works in Hilbert spaces though).  18:12 29 May 2003 (UTC)\n",
       "86098                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Leave your emotions out of it. That is the exact issue I am having with the majority of the information contained within this article - emotional and speculative.76.111.172.54\n",
       "55703                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              another thing this article needs is a description of the government's theory as to why they did a 3-year investigation, only to drop it.  apparently, pgp got out, somehow.  maybe that meant that a crime was committed, but not necessarily by zimmerman.  did the government ever have a reasonable belief that zimmerman violated the law?\n",
       "113939                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \"\\nYou may take my word for it that it is. andemu \"\n",
       "19481                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          20, 19 March 2010 (UTC)\\nI do. This isn't a science encyclopedia. Perhaps you should write for one, instead of trying to turn a general interest encyclopedia into one. ++: t/c 02\n",
       "156908                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \"\\n\\n I am being harrassed, can you help? \\n\\nI am being harrassed by  (talk|contribs) \"\n",
       "138416                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I appreciate your assistance, Dave.  I'll go take a look at your suggestions now.\n",
       "45134                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       REDIRECT Talk:Small-toothed fruit bat\n",
       "152924                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         should unless someone can provide additional citation. \\n\\nThe baboon incident, while no one seems to claim it didn't happen, may be classed as WP:FRINGE and hence non-encyclopedic example due to the fact that it was not published in a scholarly journal (notwithstanding the researcher's reputation for unethical behavior)\n",
       "138624                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \"::::Thanks for restoring the article indeed. You have hoewever ommited the history section which by ignoring this section it does not enable us to work on it and improve quality of the asection and remove any doubts of copyvio. I remember vaguely the history section being the largest of all and the article is seriously truncated of useful and important information as it stands. Cheers,  and the Mysterons \\n\\n\"\n",
       "134905                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \"\\n\\n A barnstar for you! \\n\\n  The Tireless Contributor Barnstar For your continuous effort on Bhagat Singh to make a GA. Glad to have you around, Keep It Up -)    ʈ ᶏ ɭ Ϟ \"\n",
       "79913                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The Confirmed Tracks Section \\n\\nI thought Stupid Hoe and Roman in Moscow were just buzz singles/teasers? Is it confirmed that they will appear on the album given that the first actual single is Starships?\n",
       "41396                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ok thanks nice to hear from you ok well I'll not contact you any more if it makes you feel uncomfortable we'll just keep this entre nous.  Oh by the way I moved to the US at least for 6 monhs\n",
       "79167                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         and you're a stereotyping autistic little cunt, fuck off Jew lover. (92.232.0.21  )\n",
       "75279                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The supposed loss of content was due to rewording.\n",
       "116094                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     block user:sco1996\\nDear Syrthiss.\\nsco1996 is continuing to sockpuppet none sockpuppet users causing general trouble to the site he is using inappropriate languages on pages and generally disusing the site i also know he has two accounts although i am not sure of the name of the second. please can you stop him.\\nfrom Tariq.\n",
       "10817     \"\\n\\nMachida returned to his native Brazil to face Phil Davis on August 3, 2013 at UFC 163.[44][45] In a unanimous result, Davis defeated Machida via decision.[46][47] 13 of 13 ufc media outlets scored the bout in favor of Machida.[47] Davis had takedowns near the end of rounds one and two, after neither fighter was able to mount any significant offense. Davis mounted significant offense, as it won him the fight. ESPN scored for Davis. Many UFC shills with hall passes that could be taken away and votes on the ufc rankings, but zero in the way of journalistic credentials of any discernible pedigree in journalism scored the fight 30-27 in favor of Machida.[48] UFC promoter, sport hater, and just bleed advocate, Dana White stated shortly after the fight that he had Machida winning all three rounds,[49] and later told Yahoo! Sports that \"\"Machida definitely won\"\" and \"\"MMA judging sucks\"\".[50] Fightmetric Analysis supports this, showing that Machida outstruck Phil Davis, and neutralize...\n",
       "7825                                                                                                                                                                                                                                                                                                                                        \"\\n Well, have a look at this photo, especially what the grabber is doing with his hands - it's very plausible and highly likely that there were scratches.\\n I use \"\"grabber\"\" guardedly, since a person who by force of arms takes and carries away is a robber, at least here under the common law, so a more accurate description would be \"\"attempted robber\"\".\\n As for your argument about idiocy... that's like saying rape victims are at fault by wearing skimpy dresses. What's wrong is wrong is wrong - and using violence against an innocent civilian to promote a political agenda is wrong, and you cannot justify it by the (tenuously connected) actions of another.  (Talk) \\n\\n\"\n",
       "85498                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     REDIRECT Talk:1995 South Asian Gold Cup\n",
       "16112                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nOkay well this book was published before his trial and him being \"\"discredited\"\". Doesn't that make it a reliable source? It's not the book he was sued for, that was \"\"Hitler's war\"\", published after the book being reviewed. Just to make it clear I'm not trying to whitewash the Nazis or anything and say they didn't commit war crimes, obviously they did. I am just trying to make sure both sides of an academic issue are presented.  \"\n",
       "92786                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Excuse me, I don't like being ignored...could you please respond?\n",
       "64213                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Asking some his nationality is a Racial offence. Wow wasn't aware of it.  Blocking me has shown your support towards your community. Thanku for that\n",
       "61569                                                                                                                                                                                                      Negative Support for merger.  Well logging covers many many more disciplines than electric line.  Well logging covers mudlogging, LWD, DST, etc., surely you don't plan on merging those into well logging?  Ideally well logging should look something like Well intervention where it gives brief snippets of different well logging methods and links over to them.  I think the data in well logging should be merged into the other wikipedia entries.  Finally, electric line does not always produce a log.  Perforating services and mechanical services, like those used to set plugs, packers, and cement, do not necessarily produce any well logs at all, yet they are very important aspects of wireline operations.  Entire wireline companies never produce electric line logs (namely, plug and abandonment companies)\n",
       "137788                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \"\\n\\nIf you're sure that the company did not renew the (c) on these - then the appropriate license template would be , if you're not sure, then  would be appropriate. The appropriate fair use template for these would be  (filling in the appropriate fields).  (talk) \"\n",
       "103484                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Regarding your sexuality\\nIs it true you iz a homo nigga? You is a skinny little dork fuck aren't ya? You have never had pussy have you boy? Never. You is a ninny is what you is. One one nigga. Bang blunts all day long son.\n",
       "24428                                        Poor Wolfy you are so deluded. You have never added anything of any use to the PD article. You don't even know basics. You're not a specialist. You're just a GP with all the ignorance that involves. You plainly don't keep up to date with PD because you keep on proving how dated your knowledge of it is. You keep on referring to some basic medical text. If it isn't in that book it isn't true according to you. I've read over 80 books on Parkinson's Disease. Even that isn't 5% of what I know. I spent over three years just on its biochemistry. What you know about PD biochemistry you could LITERALLY write on the back of a matchbox. As you have nothing useful to add you just revert everybody. You plainly suffer from intolerance, ignorance, conservatism and obsessions. You're detrimental to WP. So for good measure I've reverting dozens of your old edits - the ones you no longer check - just taking out the bits you added - all using different names of course.\n",
       "8609                                                                                                                                                                                                                                                                                                                                                                                         I haven't had time to read all the comments but i just want to say that this article still needs ALOT pf work, not only in wikipedia standards but also because almost every single article is written better than this one. I mean come on guys we can't let the rest of the zodiacs show us up >.>. As a fellow Pisces I agree that yes we are the best, but in the future lets try to keep the article as neutral as possible. Even I can read the article and tell that some of the people who have been editing it have been self bragging on ourselves. Also there are multiple books printed that would be reliable sources for zodiac stuff.\n",
       "106730                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               FUCK YOU! the source is the top 100 LOWEST ACCEPTANCE RATES. In what world is that not a source you asshole!\n",
       "140398                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     what are you stalking me or something?  \\nWhat are you stalking my edits or something?\n",
       "158745                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\n\\nOk, so we simply take away the info about 'one' railway and put it in a seperate section to indicate life before NXEA so as to \\n\"\"declutter\"\" the article without having to make a new one?   \"\n",
       "124513                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \"\\n Ah, shit. I can't help myself. If I understand \"\"Hodja\"\" (whose previous website id was \"\"Biophys\"\" and is currently working some kind of deal here  if I'm following along Ok) my edits had something to do with \"\"the worst area of discretionary sanctions in the entire project. Other conflict areas are nothing compare (sic) to that.\"\" What is this area?  \"\n",
       "77486                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Wikipedia Articles \\n\\nHi, Wikipedia articles are intended to be the products of teamwork. No article should be owned by one Wikipedia editor in particular. Am I correct about this? Thanks.\n",
       "121751                                                                                                                                                                                                                 \"\\n\\n\"\"Corroborating evidence\"\" is unclear and is another way of saying \"\"I don't want this information on the web-page because I am opposed to it.\"\"  As I stated before, the information should be on the page, particularly since it is biographical information that the person about whom the biography was written has stated publicly, both in the Google Video and under testimony during Charles Calderon's proposal of the porn tax bill before the California state assembly.  I am not deleting any of your information, but you are deleting mine.  If you don't approve of facts that have been stated by and individual - and they are biographical facts - then you may create an entire separate section on Lubben on this webpage.  Please refrain from deleting sources and citations.Veritas, Semper \"\n",
       "1361                                                                                                                                                                                         \"\\n\\nNo!  This is a GROUP EFFORT!  Wikipedia is a collaborative COMMUNITY and there are no school essays here.  The article needs to be more professional and adopt a better title besides the references.  This is all that needs to be done, so get off your high horse and accomplish what you want to see done.  If you have these goals, then put yourself to the test of solving this problem.  That's what I do whenever something perturbs me.  You're just looking for a fight about something you admittedly care nothing about.  How about I come by your house and criticise your gardens?  \"\"Why?\"\" You say.  \"\"Because they are too fucking ugly and I don't like the way they  don't blend in with the neighbours' yards.  So tacky, but I'm only passing by and I've never been down this road before.\"\"   15:24, 25 Feb 2005 (UTC)\"\n",
       "67392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \" \\n\\nI really don't know why I ever donated to you. Banning someone for something that happened over a month previously and then reverting my page when I request to be unbanned... not very \"\"free\"\".\\n\\n\"\n",
       "115377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \"\\nIn that case your means of simply reverting the whole thing is simply a bad edit, instead of making corrections where I may have gone wrong, you instead revert the whole thing, despite the improvements, that's just lazy editing. If you want to discuss the changes I have made further, then discuss it on the talk page. |}} \"\n",
       "128468                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2008 (UTC)\\n\\nDont sweat these fucks, man, Vitual Steve can ramm his dog, and fuck scarian hes a fucking prick.\\nthey all do suck black dick, huh bro?  20:45, 29 July\n",
       "63790                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Hey, don't be a faggot.\n",
       "146332                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You're right.  I've redirected The Sun back to The Sun (newspaper), and put a small notice on the top of the latter article. It's a big page move and there doesnt appear to be any concensus for it.\n",
       "92711                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Agreed. Removed. (  )\n",
       "7389                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Relations to other breeds \\n\\nIs there any relation to the [German Pinscher] or [Doberman] or any similar breeds?  The markings on black and tan dogs seem very similar.\n",
       "1928                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Moral Defense, you slimy toad you.\n",
       "131600                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\n\\n I think I did it. The first is OK the second one gave me \"\"No revisions can be merged. \"\".    \"\n",
       "101818                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              where'd you get that information you dont know shit about DDG\n",
       "85236                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \":He's in a group that was created as an homage to the Legion of Superheroes, he has a cousin who shares his powers and his real name is a combination of \"\"Kal\"\" and \"\"Clark\"\". It seems fairly obvious to me. (Although there's also a case to be made for Mon-El.)   \\n\\n\"\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.comment_text.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Next, we'll get the values for both our labels and the comments that will act as our training and testing data. We do this in order to get the data from pandas DataFrames to numpy arrays. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create an array called `list_classes` that contains the following classes, in this order:\n",
    "    * `'toxic'`\n",
    "    * `'severe_toxic'`\n",
    "    * `'obscene'`\n",
    "    * `'threat'`\n",
    "    * `'insult'`\n",
    "    * `'identity_hate'`\n",
    "* Store the `.values` of the DataFrame that is returned by using `list_classes` to slice the label columns from `train` (slice `list_classes` from train, and then chain it with `.values`). Store this in `y`.\n",
    "* Store the `.values` of `train['comment_text]` in `list_sentences_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train['comment_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data dictionary for this Kaggle competition, there are no missing values in either the train or the test set. However, let's quickly double check, just to be sure!\n",
    "\n",
    "Run the cell below to see if there are any missing values in either the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that there are no missing values in either training set\n",
    "train['comment_text'].isna().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Data\n",
    "\n",
    "Next, We'll need to preprocess our data. We've already learned how to do most of this by working with NLTK--however, keras also contains some excellent preprocessing packages to help prepare text data.  Since we'll be feeding this data right into a model built with keras, this has the added benefit of ensuring that our data will be in a format that our model will be able to work with, meaning that we can avoid the weird bugs that sometimes occur when working with multiple different 3rd party libraries at the same time. \n",
    "\n",
    "Our preprocessing steps are:\n",
    "\n",
    "1. **_Tokenize_** the data. \n",
    "2. Turn the tokenized text into **_Sequences_**\n",
    "3. **_Pad_** the sequences so they're all the same length. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create a `Tokenizer`, which can be found inside the `text` module we imported at the top of the lab. Set the `num_words` parameter to `20000`, so that our model only uses the 20000 most common words. \n",
    "* Convert `list_sentences_train` to a python list, and then pass it in to our tokenizer's `.fit_on_texts()` method. \n",
    "* Call the tokenizer's `texts_to_sequences()` method on `list_sentences_train` and store the result returned in `list_tokenized_train`\n",
    "* Use the `sequence` module's `pad_sequences()` method and pass in `list_tokenized_train`, as well as the parameter `maxlen=100`. Store the result returned in `X_t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This cell may take a little while to run!\n",
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list_sentences_train)\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Our Model\n",
    "\n",
    "Now that we've loaded and preprocessed our data, we're ready to begin designing our model. By now, working with keras to create and compile a model will probably feel familiar to you. To keep things simple, we've left the name of each layer below. Your job will be to create each layer, and specify the previous layer that acts as it's input (which is why so many of the layers are called `x` below--you've probably noticed this simplifies the creation process by eliminating the need to keep track of which layer is which at any given point). \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Set the `embedding_size` to `128`\n",
    "* Create an `Input` layer that takes in data of `shape=(100,)`\n",
    "* Next, create an `Embedding` layer and pass in `20000` and `embedding_size` as parameters. Make sure to specify that the Embedding layer takes in the output of the input layer as its input by ending the line with `(input_)`\n",
    "* Create a `Bidirectional` layer. Inside this layer, pass in an `LSTM()`. The parameters for the LSTM should be `25`, and `return_sequences=True`. \n",
    "* Create a `GlobalMaxPool1D` Layer\n",
    "* Create a `Dropout` layer, and pass in `0.5` as a parameter. \n",
    "* Create a `Dense` layer with `50` neurons, and set the `activation` to `'relu'`\n",
    "* Create another `Dropout` layer, and pass in `0.5` as the parameter. \n",
    "* Create a `Dense` layer with `6` neurons, and set the `activation` to `'sigmoid'`. \n",
    "* Create a `Model` and set the `inputs` to `input_` and `outputs` to `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "input_ = Input(shape=(100,))\n",
    "x = Embedding(20000, embedding_size)(input_)\n",
    "x = Bidirectional(LSTM(25, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0,5)(x)\n",
    "x = Dense(6, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've created our model, we still need to compile it.  \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Call `model.compile` and pass in the following parameters:\n",
    "    * `loss='binary_crossentropy'`\n",
    "    * `optimizer='adam'`\n",
    "    * `metrics=['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the model we've created. In the cell below, call `model.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 50)           30800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 2,593,656\n",
      "Trainable params: 2,593,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Some Checkpoints\n",
    "\n",
    "Training models like this can be tricky. Because of that, we'll make use of **_Checkpoints_** to help us periodically save our work in case things go wrong during training. \n",
    "\n",
    "We'll create two different types of checkpoints below:\n",
    "\n",
    "* A `ModelCheckpoint` that saves the best weights for our model at any given time inside an `hdf5` file. This way, if our model's performance starts to degrade at any point, we can always reload the weights from a snapshot of when it had the best possible performance. \n",
    "\n",
    "* An `EarlyStopping` checkpoint, which will stop the training early if the model goes for a certain number of epochs without any progress. \n",
    "\n",
    "For this lab, we'll only be training the model for a single epoch, so we don't actually need to use these checkpoints. However, on the job, models like this are often trained for days at a time. With training times that long, checkpoints are absolutely crucial to avoid losing days of work. There are few things more frustrating than seeing that you model was performing really well 2 days ago, but has since began to have performance degrade due to overfitting, and you have to start the training over because you forgot to set checkpoints!\n",
    "\n",
    "Run the cells below to create the checkpoints and store them in an array that we'll pass in during training. For more information on the checkpoints we've created, see the [Keras callbacks documentation](https://keras.io/callbacks/#earlystopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = 'weights_base.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoints_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=25)\n",
    "\n",
    "callbacks = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now, we're ready to train our data. Because our model contains over 1.9 million trainable parameters, this will take a little while to train! \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Call `model.fit()` and pass in the following parameters:\n",
    "    * `X_t`\n",
    "    * `y`\n",
    "    * `batch_size=32`\n",
    "    * `epochs=1`\n",
    "    * `validation_split=0.1`\n",
    "    * `callbacks=callbacks`\n",
    "    \n",
    "**_NOTE:_** Running the cell below may take 15+ minutes, depending on your machine. Run it, then go get a coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28722 samples, validate on 3192 samples\n",
      "Epoch 1/1\n",
      "28722/28722 [==============================] - 130s 5ms/step - loss: 0.1163 - acc: 0.9669 - val_loss: 0.0612 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06124, saving model to weights_base.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0e4128550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=32, epochs=1, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of over 97.8% when trained on only 20% of the data--this is excellent! If you train on the entire training set, you'll see that we achieve over 98% accuracy after only 1 epoch of training. It's safe to say our model works pretty well!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we incorporated everything we've learned about sequence models and embedding layers to build a Bidirectional LSTM Network to successfully classify toxic comments from wikipedia!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
